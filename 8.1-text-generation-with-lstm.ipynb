
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow :  2.0.0\n",
      " |-> Keras :  2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print( 'Tensorflow : ',tf.__version__)\n",
    "print( ' |-> Keras : ',keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation with LSTM\n",
    "\n",
    "This notebook contains the code samples found in Chapter 8, Section 1 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
    "\n",
    "----\n",
    "\n",
    "[...]\n",
    "\n",
    "## Implementing character-level LSTM text generation\n",
    "\n",
    "\n",
    "Let's put these ideas in practice in a Keras implementation. The first thing we need is a lot of text data that we can use to learn a \n",
    "language model. You could use any sufficiently large text file or set of text files -- Wikipedia, the Lord of the Rings, etc. In this \n",
    "example we will use some of the writings of Nietzsche, the late-19th century German philosopher (translated to English). The language model \n",
    "we will learn will thus be specifically a model of Nietzsche's writing style and topics of choice, rather than a more generic model of the \n",
    "English language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Let's start by downloading the corpus and converting it to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, we will extract partially-overlapping sequences of length `maxlen`, one-hot encode them and pack them in a 3D Numpy array `x` of \n",
    "shape `(sequences, maxlen, unique_characters)`. Simultaneously, we prepare a array `y` containing the corresponding targets: the one-hot \n",
    "encoded characters that come right after each extracted sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 200281\n",
      "Unique characters: 59\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Our network is a single `LSTM` layer followed by a `Dense` classifier and softmax over all possible characters. But let us note that \n",
    "recurrent neural networks are not the only way to do sequence data generation; 1D convnets also have proven extremely successful at it in \n",
    "recent times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(keras.layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our targets are one-hot encoded, we will use `categorical_crossentropy` as the loss to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the language model and sampling from it\n",
    "\n",
    "\n",
    "Given a trained model and a seed text snippet, we generate new text by repeatedly:\n",
    "\n",
    "* 1) Drawing from the model a probability distribution over the next character given the text available so far\n",
    "* 2) Reweighting the distribution to a certain \"temperature\"\n",
    "* 3) Sampling the next character at random according to the reweighted distribution\n",
    "* 4) Adding the new character at the end of the available text\n",
    "\n",
    "This is the code we use to reweight the original probability distribution coming out of the model, \n",
    "and draw a character index from it (the \"sampling function\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finally, this is the loop where we repeatedly train and generated text. We start generating text using a range of different temperatures \n",
    "after every epoch. This allows us to see how the generated text evolves as the model starts converging, as well as the impact of \n",
    "temperature in the sampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 24s 121us/sample - loss: 1.9687\n",
      "--- Generating with seed: \"hat they cannot\n",
      "refrain from laughter even in holy matters.\n",
      "\"\n",
      "------ temperature: 0.2\n",
      "hat they cannot\n",
      "refrain from laughter even in holy matters.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=must and stand of the stall to the stance of the strong that the stall to the stall to the stand of the man in the stall to the stand in the stand of the most and the stall to which the stall to the stall to the stance of the stand to the stall to the stall to the stall to the stance of the stance of the master of the stand of the stall that it is all they it is the stall to the stall in th\n",
      "------ temperature: 0.5\n",
      "stall that it is all they it is the stall to the stall in the most of the stoust know and it as obder that it that we contlee in the\n",
      "contrist in the sention to the orring for they ver that stord as he be the last with stood it is the develousion of the beact that self-man in be adays, that there is all not it would that pather for the stapent to be a sast of the\n",
      "stand to their the listing to be indistousial inclunion of the still to stall to the stelincy o\n",
      "------ temperature: 1.0\n",
      "distousial inclunion of the still to stall to the stelincy of puspose wime xesical ofathoo. and charming tomat age consubong of he is alarromaly to when a, a\n",
      "condlureinalition in imsoderousang\n",
      "meliel be sudi's which one, or foils one that list, like one, in for thereke is  ectilitym!with ruse to doves this knowleds\n",
      "of of himselves, what mankens of the rong of thoy hows; ut in-right with of how from haves, they lire apprsiupenlerely man mapk to ferm within \n",
      "------ temperature: 1.2\n",
      "m haves, they lire apprsiupenlerely man mapk to ferm within wi hitherto, just be\n",
      "doseld. that even be the ?wilnokly wanfouts that his, a cake and,\n",
      "vety ope equal dextemet, all rup tour \"but noclofical part dut, with freatanny, and a.\n",
      "makerial histeaanishion!\"\n",
      "meanhat world, tkith and exprssationorcal hifrefiring leg.tur othed that re heosunes-ligit, \"ttine obence do.\n",
      "honed ourself-inrefitatith of ristaniusto: hisle, canmhion only soust and youd: \"that shen\n",
      "epoch 2\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 16s 82us/sample - loss: 1.6150\n",
      "--- Generating with seed: \" countless ceremonies\n",
      "are occasioned, and finally, when thei\"\n",
      "------ temperature: 0.2\n",
      " countless ceremonies\n",
      "are occasioned, and finally, when their same to the sense of the sense of the something the something to the something to be something the sense and disciver of the sense of the sense of the subjection of the sense of the sense of the sense of the spiritual and such the sense of the sense of the sense of the sense of the sense of the moral more in the something to the moral promals in the something the sense of the self and say, to th\n",
      "------ temperature: 0.5\n",
      "romals in the something the sense of the self and say, to the something with the werness of the self to himself to be also the bad to hard its to the sense to the most contradicate men of the surceptions to rebary the contrain that the sonce and the something and exception to one findly into the discovered such the exolocical that us with the surposing that sensure, to the discovered and wither the strengthing hit europe, and more his originate position of\n",
      "------ temperature: 1.0\n",
      "e strengthing hit europe, and more his originate position of the\n",
      "ear dundise\n",
      "hithertue to one feecient of somely we perhaps\n",
      "brea, also,\"oinves govety supe-though over adquasius. the bure, and thought ty, new, under moral\n",
      "instances of the most aken to thoughts, the stingharitations consiced\n",
      "to live or whativevtes althoughter it\n",
      "is conclence,\n",
      "own to tause, and granlitationss of lipe, benenstion of thing of the pard, which is not clusies of in his impland now\n",
      "------ temperature: 1.2\n",
      "hing of the pard, which is not clusies of in his impland now ore sleashning roce to upbrogive (without eshye known amowd a namultor mingervars hirder--all will--wi hard\n",
      "mea we; the sp(. the kind\"\n",
      "fromkevers and\n",
      "reastoture him marely cievcedd to fumully attath of leads\"kwolscewit\n",
      "cormens of not\n",
      "to him\n",
      "osiveniousnakeness frontinations, which soue:  the neom. the unaid mind the  bad\n",
      "to much intonesencl its in\n",
      "goin rutities; in our trage.=cn, well by much unxa\n",
      "epoch 3\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 16s 79us/sample - loss: 1.5260\n",
      "--- Generating with seed: \" as a stain upon a god-like creation. there still apparently\"\n",
      "------ temperature: 0.2\n",
      " as a stain upon a god-like creation. there still apparently in the soul in the consideration of the interponting in the south and morality in it is such the consequently and the considered and the spiritual and all the sense and in the consequently and the consideration of the soul and result to the soul and with a considere and in the consequence of the sense of the consequently that it is the sense and still as in the soul of the consequently and into t\n",
      "------ temperature: 0.5\n",
      "ense and still as in the soul of the consequently and into the stander of the facult and doman that which is for exercise and in the presence of a something it is one is man is\n",
      "all in the consequently he not in evil and of his dispurieves of prodes of some of so the exhasiaguagerous our existence of disperial and in untersonal and a something it is nature. a man and ideases of thing is the responsible and such he self of the complenee of the contray to the\n",
      "------ temperature: 1.0\n",
      "ible and such he self of the complenee of the contray to the life and in ances velarture.=--cossature--it the madacical is all truth--on\n",
      " t\"\n",
      "one \"most longing itself- the most cispecid: really to any only intelf-cannoty inress,\n",
      "but which be is patten---are be\n",
      "spioce\n",
      "are himself, to expectate and know\n",
      "viving ancient lhy prancion, his our excence, hewa) from men anowed of the consequently or varticign-farn to\n",
      "critiality of gurtificene?\n",
      "\"free of conceivated  \n",
      "------ temperature: 1.2\n",
      "gn-farn to\n",
      "critiality of gurtificene?\n",
      "\"free of conceivated  our corissker. what\n",
      "feer conscructre.\n",
      "thereow caploble founds.\n",
      "\n",
      "\n",
      "1it\n",
      "impuls at work iagain, rusting from only german alto a mo. indal\" sodating i always appations receraid or.. it surfennived (imittologa! even in caosrough baln\" nor.\n",
      "the (a. homen ano\n",
      "quitent, evit untery becomestrumently-grest\n",
      "thoung--which on a spuiled know loveboiness,\n",
      "as plaw exint pures\n",
      "opinigh as replait after consequence of\n",
      "epoch 4\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 16s 79us/sample - loss: 1.4804\n",
      "--- Generating with seed: \"favourable conditions. on\n",
      "the other hand, it is known by the\"\n",
      "------ temperature: 0.2\n",
      "favourable conditions. on\n",
      "the other hand, it is known by the sunces of the sense of the other of the condition of the tradity of the consciously and the such in the sense of the sense of the sense of the greate of the simply in the soul of the same the spirit of the sense of the permanines of the suncess of the standard and such and the world and deception of the superate of the fact and such a spirit of the most such a many and the sense of the world with\n",
      "------ temperature: 0.5\n",
      "irit of the most such a many and the sense of the world with it is the tradity the referred the other and befine of the morality of himself of the morality and contrands of general pastions and the sunse--and such even we can be defined to himself to the same to the philosophers of the some in part in the endhisered and something the will for the charming the condition and made and such an assertions of the \"more personaliss of the good in the independe an\n",
      "------ temperature: 1.0\n",
      "ons of the \"more personaliss of the good in the independe and it romal toomy have that insoluto and nature--was net the causoury spiriting undetiness of the property and landory of the eflive and certain exercialts to to vivig !pist the tradiality, caplicr as under that thet windriding aleved, who simple alsoes emitreer\n",
      "tronors alivon good others.--such its loter\" of ragery, knows reason and intowedine, and findslemen possibility and axpegnitude. throus co\n",
      "------ temperature: 1.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edine, and findslemen possibility and axpegnitude. throus conduct tottiness higher 1joytomih in higher betpee upon the\n",
      "prourtesh, higher equalistines and de\"mwerophy of\n",
      "flastionsrado. to extented sels\n",
      "doon wene\n",
      "the tendinede which contequence, means after pnot fuicurader that\n",
      "is odany of underediltunt--whethers are hercounding amongs as younne hamm, discive.\n",
      "und evilied a shilled fordanion. dorse dinckeby for nature. as net\n",
      "also, suspinitus judiom the cosd\n",
      "epoch 5\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 16s 80us/sample - loss: 1.4496\n",
      "--- Generating with seed: \"he period\n",
      "of lower organisms has been handed down to man the\"\n",
      "------ temperature: 0.2\n",
      "he period\n",
      "of lower organisms has been handed down to man the same the man and the south of the conscience of the most the sense of the most the there is the most superficiality and the most internam of the most the most distrust and spirit of the state of the interrignation of the most state of the south the most the conscience of the fact the spirit and the most states and the expression of the same the altered to the things to the most strength of the gr\n",
      "------ temperature: 0.5\n",
      "ame the altered to the things to the most strength of the great be disposed to divident to the\n",
      "example of the reason the general distressed that as it stand of the man in the most thing is one will every even the germans himself on the individual history of the great the feat of hold and south and superficial and the souther are interer the love the past of the way, of the will the morality and distrust of the souther in the most to the morality of the res\n",
      "------ temperature: 1.0\n",
      "strust of the souther in the most to the morality of the resurption of aims to from\n",
      "assert.wher the tilly it nothing and will, for modeves untodative in even thus.\n",
      "\n",
      "\n",
      "1\"\n",
      "\n",